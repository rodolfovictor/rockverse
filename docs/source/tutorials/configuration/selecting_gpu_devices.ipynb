{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPUs\n",
    "\n",
    "The speed of RockVerse routines can be greatly enhanced by taking advantage of GPU devices.\n",
    "\n",
    "RockVerse's internal distribution strategies can utilize multiple GPU devices simultaneously and will prioritize executing operations on GPUs whenever they are available. This process is transparent to the user, allowing for seamless integration without the need for manual configuration.\n",
    "\n",
    "At import time, RockVerse calls [Numba](https://numba.readthedocs.io/en/stable/index.html) \n",
    "and maps available GPU devices. You can manage these devices using the library-wide ``config`` object in RockVerse.\n",
    "\n",
    "## Check for Availability\n",
    "\n",
    "There are specific methods for managing GPU devices at runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices:\n",
      "GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ad64cd83-d3d5-a418-1272-37181609ab5c)\n",
      "GPU 1: Tesla V100-SXM2-32GB (UUID: GPU-dbff0259-af71-fbf6-bac4-ff7278a00a12)\n",
      "GPU 2: Tesla V100-SXM2-32GB (UUID: GPU-44331e7a-a604-1c8b-6f1f-799e78d1e9c2)\n",
      "GPU 3: Tesla V100-SXM2-32GB (UUID: GPU-d10bfadb-d96f-9347-c449-7d202fd3ba96)\n",
      "GPU 4: Tesla V100-SXM2-32GB (UUID: GPU-e16c7693-2e5b-47a7-1d12-2d6c23011cf8)\n",
      "GPU 5: Tesla V100-SXM2-32GB (UUID: GPU-c36418e8-4138-6cac-27f9-71f7a01dc9e7)\n",
      "GPU 6: Tesla V100-SXM2-32GB (UUID: GPU-8a0b5b3e-b301-ea11-f89f-c224a926edcd)\n",
      "GPU 7: Tesla V100-SXM2-32GB (UUID: GPU-2b2fd0ef-7a2b-fded-012f-0ae9c20f2acd)\n",
      "\n",
      "Selected GPU devices:\n",
      "GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ad64cd83-d3d5-a418-1272-37181609ab5c)\n",
      "GPU 1: Tesla V100-SXM2-32GB (UUID: GPU-dbff0259-af71-fbf6-bac4-ff7278a00a12)\n",
      "GPU 2: Tesla V100-SXM2-32GB (UUID: GPU-44331e7a-a604-1c8b-6f1f-799e78d1e9c2)\n",
      "GPU 3: Tesla V100-SXM2-32GB (UUID: GPU-d10bfadb-d96f-9347-c449-7d202fd3ba96)\n",
      "GPU 4: Tesla V100-SXM2-32GB (UUID: GPU-e16c7693-2e5b-47a7-1d12-2d6c23011cf8)\n",
      "GPU 5: Tesla V100-SXM2-32GB (UUID: GPU-c36418e8-4138-6cac-27f9-71f7a01dc9e7)\n",
      "GPU 6: Tesla V100-SXM2-32GB (UUID: GPU-8a0b5b3e-b301-ea11-f89f-c224a926edcd)\n",
      "GPU 7: Tesla V100-SXM2-32GB (UUID: GPU-2b2fd0ef-7a2b-fded-012f-0ae9c20f2acd)\n"
     ]
    }
   ],
   "source": [
    "import rockverse as rv\n",
    "\n",
    "# Importing RockVerse creates the 'config' object as an instance of the\n",
    "# rockverse.configuration.Config class.\n",
    "\n",
    "# Let's use the print_available_gpus method to check for available devices.\n",
    "print(\"Available GPU devices:\")\n",
    "rv.config.print_available_gpus()\n",
    "\n",
    "# By default, RockVerse will utilize all available devices to execute its tasks.\n",
    "print(\"\\nSelected GPU devices:\")\n",
    "rv.config.print_selected_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the devices using ``rockverse.config``\n",
    "\n",
    "The machine used in this tutorial has 8 Tesla V100-SXM2-32GB GPUs available.\n",
    "\n",
    "As seen above, RockVerse will by default utilize all available devices to execute its tasks.\n",
    "This behavior can be modified by setting a list of device indices in ``config['selected_gpus']``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old list of selected GPU devices: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "New device list: [1, 2, 4, 5]\n",
      "\n",
      "Selected GPU devices:\n",
      "GPU 1: Tesla V100-SXM2-32GB (UUID: GPU-dbff0259-af71-fbf6-bac4-ff7278a00a12)\n",
      "GPU 2: Tesla V100-SXM2-32GB (UUID: GPU-44331e7a-a604-1c8b-6f1f-799e78d1e9c2)\n",
      "GPU 4: Tesla V100-SXM2-32GB (UUID: GPU-e16c7693-2e5b-47a7-1d12-2d6c23011cf8)\n",
      "GPU 5: Tesla V100-SXM2-32GB (UUID: GPU-c36418e8-4138-6cac-27f9-71f7a01dc9e7)\n"
     ]
    }
   ],
   "source": [
    "# Print the original indices of selected devices\n",
    "print(f\"Old list of selected GPU devices: {rv.config['selected_gpus']}\")\n",
    "\n",
    "# Change the list of selected devices\n",
    "rv.config['selected_gpus'] = [1, 2, 4, 5]\n",
    "print(f\"New device list: {rv.config['selected_gpus']}\")\n",
    "\n",
    "print(\"\\nSelected GPU devices:\")\n",
    "rv.config.print_selected_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use any iterable of integers, in any order, to set the selected devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected GPU devices: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# All this are valid commands and generate the same outcome\n",
    "rv.config['selected_gpus'] = (0, 1, 2, 3) # tuple\n",
    "rv.config['selected_gpus'] = [1, 2, 0, 3] # list\n",
    "rv.config['selected_gpus'] = {0, 1, 3, 2} # set\n",
    "rv.config['selected_gpus'] = [0, 1, 3, 2, 3] # repeated index will be filtered out\n",
    "rv.config['selected_gpus'] = range(4) #range\n",
    "print(f\"New selected GPU devices: {rv.config['selected_gpus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set empty list to disable GPU processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "rv.config['selected_gpus'] = []\n",
    "print(f\"New selected GPU devices: {rv.config['selected_gpus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using invalid indices will raise exceptions, such as \n",
    "```python\n",
    "# This will raise a runtime error: maximum index is 7 in this example.\n",
    "rv.config['selected_gpus'] = (0, 1, 2, 3, 11)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the devices using the config context manager\n",
    "\n",
    "The config context manager allows you to temporarily modify the configuration settings for GPU selection within a specific block of code. This is particularly useful when you want to experiment with different device selections without permanently altering your configuration.\n",
    "\n",
    "By using the context manager, you can easily revert to the original settings once the block is exited, ensuring that your application maintains its intended behavior beyond the temporary changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permanent device list: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "This block device list: [2, 4, 6]\n",
      "Back to permanent device list: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# Default to full device list\n",
    "rv.config['selected_gpus'] = range(8)\n",
    "print(f\"Permanent device list: {rv.config['selected_gpus']}\")\n",
    "\n",
    "# Temporary reassignment with the context manager\n",
    "with rv.config_context({'selected_gpus': [2, 4, 6]}):\n",
    "    print(f\"This block device list: {rv.config['selected_gpus']}\")\n",
    "\n",
    "# After the with block, everything goes back to normal\n",
    "print(f\"Back to permanent device list: {rv.config['selected_gpus']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using several GPUs\n",
    "\n",
    "Each MPI process will use only one device, which is automatically selected at runtime based on the selection list through the ``rank_select_gpu`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected devices:\n",
      "GPU 1: Tesla V100-SXM2-32GB (UUID: GPU-dbff0259-af71-fbf6-bac4-ff7278a00a12)\n",
      "GPU 2: Tesla V100-SXM2-32GB (UUID: GPU-44331e7a-a604-1c8b-6f1f-799e78d1e9c2)\n",
      "GPU 4: Tesla V100-SXM2-32GB (UUID: GPU-e16c7693-2e5b-47a7-1d12-2d6c23011cf8)\n",
      "GPU 5: Tesla V100-SXM2-32GB (UUID: GPU-c36418e8-4138-6cac-27f9-71f7a01dc9e7)\n",
      "\n",
      "Running 1 MPI process(es):\n",
      "   Rank 0 using device 1\n"
     ]
    }
   ],
   "source": [
    "rv.config['selected_gpus'] = [1, 2, 4, 5]\n",
    "\n",
    "print(\"Selected devices:\")\n",
    "rv.config.print_selected_gpus()\n",
    "\n",
    "print(f\"\\nRunning {rv.mpi_nprocs} MPI process(es):\")\n",
    "print(f\"   Rank {rv.mpi_rank} using device {rv.config.rank_select_gpu()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize more than one device, you need to run with multiple MPI processes.\n",
    "\n",
    "Let's illustrate this directly within this Jupyter Notebook, \n",
    "using [ipyparallel](https://ipyparallel.readthedocs.io/).\n",
    "\n",
    "We will create a cluster with a set of 8 MPI engines. RockVerse will automatically assign one MPI process to each GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f8f57722b54815b715bb08d68cc2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "\n",
    "# Create an MPI cluster with 8 engines\n",
    "cluster = ipp.Cluster(engines=\"mpi\", n=8)\n",
    "\n",
    "# Start and connect to the cluster\n",
    "rc = cluster.start_and_connect_sync()\n",
    "\n",
    "# Enable IPython magics for parallel processing\n",
    "rc[:].activate()\n",
    "\n",
    "# Now we have the %%px cell magic, which will direct Jupyter to run in the parallel cluster we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6854b9066f2b4c35b9a7b7fd9e9eee86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/8 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Selected devices:\n",
       "GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ad64cd83-d3d5-a418-1272-37181609ab5c)\n",
       "GPU 1: Tesla V100-SXM2-32GB (UUID: GPU-dbff0259-af71-fbf6-bac4-ff7278a00a12)\n",
       "GPU 2: Tesla V100-SXM2-32GB (UUID: GPU-44331e7a-a604-1c8b-6f1f-799e78d1e9c2)\n",
       "GPU 3: Tesla V100-SXM2-32GB (UUID: GPU-d10bfadb-d96f-9347-c449-7d202fd3ba96)\n",
       "GPU 4: Tesla V100-SXM2-32GB (UUID: GPU-e16c7693-2e5b-47a7-1d12-2d6c23011cf8)\n",
       "GPU 5: Tesla V100-SXM2-32GB (UUID: GPU-c36418e8-4138-6cac-27f9-71f7a01dc9e7)\n",
       "GPU 6: Tesla V100-SXM2-32GB (UUID: GPU-8a0b5b3e-b301-ea11-f89f-c224a926edcd)\n",
       "GPU 7: Tesla V100-SXM2-32GB (UUID: GPU-2b2fd0ef-7a2b-fded-012f-0ae9c20f2acd)\n",
       "\n",
       "Running 8 MPI process(es)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "import rockverse as rv\n",
    "\n",
    "if rv.mpi_rank == 0:\n",
    "    print(\"Selected devices:\")\n",
    "    rv.config.print_selected_gpus()\n",
    "    print(f\"\\nRunning {rv.mpi_nprocs} MPI process(es)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Rank 0 using device 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Rank 1 using device 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Rank 2 using device 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] Rank 4 using device 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Rank 3 using device 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] Rank 5 using device 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] Rank 6 using device 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] Rank 7 using device 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "print(f\"Rank {rv.mpi_rank} using device {rv.config.rank_select_gpu()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scenarios where there are more MPI processes than GPU devices, RockVerse will distribute the workload as evenly as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] Rank 1 using device 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Rank 3 using device 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Rank 0 using device 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Rank 2 using device 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] Rank 7 using device 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] Rank 6 using device 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] Rank 4 using device 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] Rank 5 using device 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "rv.config['selected_gpus'] = [1, 2, 4, 5]\n",
    "print(f\"Rank {rv.mpi_rank} using device {rv.config.rank_select_gpu()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open another cluster with 32 engines and observe how the devices are assigned. \n",
    "Fisrt we need to close the current cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object Cluster.stop_cluster at 0x7feed86c6f60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.stop_cluster() # Close the current cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then call ipyparallel again to create the new cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 32 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0fc88d99d644ad8af9378e96f24dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#New cluster with 32 engines\n",
    "cluster = ipp.Cluster(engines=\"mpi\", n=32)\n",
    "rc = cluster.start_and_connect_sync()\n",
    "rc[:].activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the device assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c43b523ed64f64bdfa740553d64bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/32 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:29] Rank 29 using device 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:23] Rank 23 using device 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:24] Rank 24 using device 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:9] Rank 9 using device 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:18] Rank 18 using device 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:28] Rank 28 using device 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] Rank 7 using device 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] Rank 5 using device 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:25] Rank 25 using device 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Rank 0 using device 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] Rank 4 using device 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:20] Rank 20 using device 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:8] Rank 8 using device 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:22] Rank 22 using device 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:17] Rank 17 using device 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:26] Rank 26 using device 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] Rank 6 using device 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Rank 2 using device 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Rank 3 using device 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:14] Rank 14 using device 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:27] Rank 27 using device 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:10] Rank 10 using device 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:15] Rank 15 using device 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:13] Rank 13 using device 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:11] Rank 11 using device 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:30] Rank 30 using device 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:21] Rank 21 using device 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:31] Rank 31 using device 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:12] Rank 12 using device 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Rank 1 using device 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:16] Rank 16 using device 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:19] Rank 19 using device 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "import rockverse as rv\n",
    "print(f\"Rank {rv.mpi_rank} using device {rv.config.rank_select_gpu()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can play with MPI collective calls to better organize this output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Device assignment:\n",
       "GPU 0: ranks [0, 8, 16, 24]\n",
       "GPU 1: ranks [1, 9, 17, 25]\n",
       "GPU 2: ranks [2, 10, 18, 26]\n",
       "GPU 3: ranks [3, 11, 19, 27]\n",
       "GPU 4: ranks [4, 12, 20, 28]\n",
       "GPU 5: ranks [5, 13, 21, 29]\n",
       "GPU 6: ranks [6, 14, 22, 30]\n",
       "GPU 7: ranks [7, 15, 23, 31]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "\n",
    "def print_rank_list():\n",
    "    rank_list = {k: [] for k in rv.config['selected_gpus']}\n",
    "    for rank in range(rv.mpi_nprocs):\n",
    "        device = rv.mpi_comm.bcast(rv.config.rank_select_gpu(), root=rank)\n",
    "        rank_list[device].append(rank)\n",
    "\n",
    "    if mpi_rank == 0:\n",
    "        print(\"Device assignment:\")\n",
    "        for k in sorted(rank_list.keys()):\n",
    "            print(f\"GPU {k}: ranks {rank_list[k]}\")\n",
    "\n",
    "print_rank_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test with restricted lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Device assignment:\n",
       "GPU 0: ranks [0, 5, 10, 15, 20, 25, 30]\n",
       "GPU 1: ranks [1, 6, 11, 16, 21, 26, 31]\n",
       "GPU 2: ranks [2, 7, 12, 17, 22, 27]\n",
       "GPU 3: ranks [3, 8, 13, 18, 23, 28]\n",
       "GPU 4: ranks [4, 9, 14, 19, 24, 29]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "with rv.config_context({'selected_gpus': range(5)}):\n",
    "    print_rank_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Device assignment:\n",
       "GPU 1: ranks [0, 4, 8, 12, 16, 20, 24, 28]\n",
       "GPU 3: ranks [1, 5, 9, 13, 17, 21, 25, 29]\n",
       "GPU 5: ranks [2, 6, 10, 14, 18, 22, 26, 30]\n",
       "GPU 7: ranks [3, 7, 11, 15, 19, 23, 27, 31]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "with rv.config_context({'selected_gpus': [1, 3, 5, 7]}):\n",
    "    print_rank_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Device assignment:\n",
       "GPU 0: ranks [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30]\n",
       "GPU 1: ranks [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31]\n",
       "GPU 7: ranks [2, 5, 8, 11, 14, 17, 20, 23, 26, 29]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "with rv.config_context({'selected_gpus': [0, 1, 7]}):\n",
    "    print_rank_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rockverse-zarr3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
